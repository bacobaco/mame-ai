# üïπÔ∏è MAME AI Training Framework

[![Fran√ßais](https://img.shields.io/badge/Langue-Fran√ßais-blue)](#fran√ßais) [![English](https://img.shields.io/badge/Language-English-red)](#english)

---

<a name="fran√ßais"></a>
# üá´üá∑ Fran√ßais

Ce projet est un framework complet permettant d'entra√Æner des agents d'Intelligence Artificielle (Reinforcement Learning) sur des jeux d'arcade classiques (Space Invaders, Pac-Man) via l'√©mulateur **MAME**.

Il utilise une architecture **Client-Serveur** o√π Python (le cerveau) communique avec MAME (le corps) via un socket TCP local, permettant un contr√¥le frame-par-frame et une lecture directe de la m√©moire RAM du jeu.

---

## üöÄ Fonctionnement & Architecture

Le syst√®me repose sur trois composants principaux :

1.  **MAME & Lua Script (`PythonBridgeSocket.lua`)** :
    *   MAME ex√©cute le jeu.
    *   Un script Lua int√©gr√© agit comme serveur. Il expose les adresses m√©moire (RAM) et √©coute les commandes d'input.
    *   Il synchronise l'√©mulation avec l'IA via un m√©canisme de `wait_for` (attente de commandes).

2.  **Interface de Communication (`MameCommSocket.py`)** :
    *   G√®re la connexion TCP brute entre Python et Lua.
    *   Envoie des commandes (ex: `execute P1_Button_1(1)`) et re√ßoit les √©tats m√©moire.

3.  **Cerveau IA (`AI_Mame.py` & Scripts de Jeu)** :
    *   Impl√©mente des algorithmes de **Deep Reinforcement Learning** (Rainbow DQN, DreamerV2).
    *   **`invaders.py` / `pacman.py`** : Wrappers sp√©cifiques √† chaque jeu qui d√©finissent les r√©compenses (rewards), extraient l'√©tat (pixels ou RAM) et g√®rent la boucle d'entra√Ænement.

```mermaid
graph LR
    A[MAME Emulator] -- RAM & Video --> B(Lua Script Server)
    B -- TCP Socket --> C(Python Client)
    C -- Actions (Joy/Btn) --> B
    C -- PyTorch Model --> D[Neural Network]
```

---

## ‚ú® Fonctionnalit√©s Cl√©s

*   **Algorithmes Avanc√©s (Rainbow DQN)** :
    *   **Double DQN** & **Dueling DQN** pour une meilleure estimation des valeurs.
    *   **Noisy Nets** pour une exploration dynamique (remplace Epsilon-Greedy).
    *   **Prioritized Experience Replay (PER)** pour apprendre des moments importants.
    *   **N-Step Learning** pour une vision √† plus long terme.
*   **Support Multi-Architectures** :
    *   **CNN (Convolutional Neural Network)** : L'IA "voit" l'√©cran (pixels bruts ou redimensionn√©s).
    *   **MLP (Multi-Layer Perceptron)** : L'IA lit directement la RAM (positions X/Y, √©tats).
*   **Outils de Visualisation** :
    *   Serveur Web int√©gr√© (Flask) pour suivre les courbes de score en temps r√©el.
    *   G√©n√©ration de graphiques `.png` automatiques.
    *   Enregistrement vid√©o des meilleures parties.

---

## üìÇ Structure du Projet

| Fichier | Description |
| :--- | :--- |
| `AI_Mame.py` | **C≈ìur de l'IA**. Contient les classes `DQNTrainer`, `DQNModel` (PyTorch), et le `ReplayBuffer`. |
| `invaders.py` | Script principal pour **Space Invaders**. G√®re les rewards sp√©cifiques (tuer alien, √©viter bombe). |
| `pacman.py` | Script principal pour **Pac-Man**. G√®re la lecture de la VRAM (labyrinthe) et des sprites. |
| `invaders_robot.py` | Un bot algorithmique (non-IA) pour Space Invaders, bas√© sur des r√®gles logiques. |
| `MameCommSocket.py` | G√®re le protocole de communication bas niveau avec Lua. |
| `ScreenRecorder.py` | Utilitaire pour capturer l'√©cran de jeu. |
| `dreamerv2.py` | Impl√©mentation exp√©rimentale de l'algo DreamerV2 (Model-Based RL). |

---

## üõ†Ô∏è Installation et Configuration

### Pr√©-requis
*   Python 3.8+
*   Biblioth√®ques : `torch`, `numpy`, `matplotlib`, `flask`, `keyboard`, `pygame`, `pywin32`.
*   **MAME** install√© avec les ROMs n√©cessaires (`invaders`, `pacman`).

### Configuration des Chemins
‚ö†Ô∏è **Important** : Les scripts Python contiennent des chemins absolus qu'il faut adapter √† votre machine.
Ouvrez `invaders.py` ou `pacman.py` et modifiez la m√©thode `launch_mame` :

```python
command = [
    r"C:\Chemin\Vers\Votre\mame.exe", # <--- Modifier ici
    "-autoboot_script", r"C:\Chemin\Vers\Plugins\PythonBridgeSocket.lua", # <--- Et ici
    ...
]
```

---

## üéÆ Utilisation

### Lancer un entra√Ænement
Ex√©cutez simplement le script correspondant au jeu :

```bash
python invaders.py
# ou
python pacman.py
```

### Raccourcis Clavier (Pendant l'entra√Ænement)
Le focus doit √™tre sur la fen√™tre du terminal/console pour que les touches fonctionnent.

| Touche | Action |
| :--- | :--- |
| **F2** | üõë Arr√™t propre et sauvegarde du mod√®le. |
| **F3** | üêû D√©sactiver le mode Debug (console moins verbeuse). |
| **F4** | üêõ Changer le niveau de Debug (0-3). |
| **F5** | ‚è© Augmenter la vitesse d'√©mulation (Throttle). |
| **F6** | ‚è™ R√©duire la vitesse d'√©mulation. |
| **F7** | üìä G√©n√©rer manuellement le graphique des scores. |
| **F8** | üëÅÔ∏è Afficher ce que l'IA "voit" (Input Frame/State). |
| **F9** | üîÑ Basculer entre mode **Exploration** (Apprentissage) et **Exploitation** (Jeu pur). |
| **F10/F11** | üéõÔ∏è Ajuster manuellement le taux d'exploration (Epsilon) (si NoisyNet inactif). |

---

## üìä Suivi des R√©sultats
*   Les logs sont affich√©s dans la console.
*   Un serveur web local est lanc√© sur `http://localhost:5000` pour voir les graphiques d'√©volution.
*   Les mod√®les (`.pth`) et les buffers (`.buffer`) sont sauvegard√©s automatiquement √† la racine.

---

<a name="english"></a>
# üá¨üáß English

This project is a complete framework for training Artificial Intelligence (Reinforcement Learning) agents on classic arcade games (Space Invaders, Pac-Man) via the **MAME** emulator.

It uses a **Client-Server** architecture where Python (the brain) communicates with MAME (the body) via a local TCP socket, allowing frame-by-frame control and direct reading of the game's RAM.

---

## üöÄ Operation & Architecture

The system relies on three main components:

1.  **MAME & Lua Script (`PythonBridgeSocket.lua`)**:
    *   MAME runs the game.
    *   An embedded Lua script acts as a server. It exposes memory addresses (RAM) and listens for input commands.
    *   It synchronizes emulation with the AI via a `wait_for` mechanism (waiting for commands).

2.  **Communication Interface (`MameCommSocket.py`)**:
    *   Handles the raw TCP connection between Python and Lua.
    *   Sends commands (e.g., `execute P1_Button_1(1)`) and receives memory states.

3.  **AI Brain (`AI_Mame.py` & Game Scripts)**:
    *   Implements **Deep Reinforcement Learning** algorithms (Rainbow DQN, DreamerV2).
    *   **`invaders.py` / `pacman.py`**: Game-specific wrappers that define rewards, extract state (pixels or RAM), and manage the training loop.

```mermaid
graph LR
    A[MAME Emulator] -- RAM & Video --> B(Lua Script Server)
    B -- TCP Socket --> C(Python Client)
    C -- Actions (Joy/Btn) --> B
    C -- PyTorch Model --> D[Neural Network]
```

---

## ‚ú® Key Features

*   **Advanced Algorithms (Rainbow DQN)**:
    *   **Double DQN** & **Dueling DQN** for better value estimation.
    *   **Noisy Nets** for dynamic exploration (replaces Epsilon-Greedy).
    *   **Prioritized Experience Replay (PER)** to learn from important moments.
    *   **N-Step Learning** for longer-term vision.
*   **Multi-Architecture Support**:
    *   **CNN (Convolutional Neural Network)**: The AI "sees" the screen (raw or resized pixels).
    *   **MLP (Multi-Layer Perceptron)**: The AI reads RAM directly (X/Y positions, states).
*   **Visualization Tools**:
    *   Integrated Web Server (Flask) to track score curves in real-time.
    *   Automatic `.png` graph generation.
    *   Video recording of best games.

---

## üìÇ Project Structure

| File | Description |
| :--- | :--- |
| `AI_Mame.py` | **AI Core**. Contains `DQNTrainer`, `DQNModel` (PyTorch), and `ReplayBuffer` classes. |
| `invaders.py` | Main script for **Space Invaders**. Handles specific rewards (kill alien, avoid bomb). |
| `pacman.py` | Main script for **Pac-Man**. Handles VRAM reading (maze) and sprites. |
| `invaders_robot.py` | Algorithmic bot (non-AI) for Space Invaders, based on logic rules. |
| `MameCommSocket.py` | Handles low-level communication protocol with Lua. |
| `ScreenRecorder.py` | Utility to capture game screen. |
| `dreamerv2.py` | Experimental implementation of DreamerV2 algo (Model-Based RL). |

---

## üõ†Ô∏è Installation and Configuration

### Prerequisites
*   Python 3.8+
*   Libraries: `torch`, `numpy`, `matplotlib`, `flask`, `keyboard`, `pygame`, `pywin32`.
*   **MAME** installed with necessary ROMs (`invaders`, `pacman`).

### Path Configuration
‚ö†Ô∏è **Important**: Python scripts contain absolute paths that must be adapted to your machine.
Open `invaders.py` or `pacman.py` and modify the `launch_mame` method:

```python
command = [
    r"C:\Path\To\Your\mame.exe", # <--- Modify here
    "-autoboot_script", r"C:\Path\To\Plugins\PythonBridgeSocket.lua", # <--- And here
    ...
]
```

---

## üéÆ Usage

### Start Training
Simply run the script corresponding to the game:

```bash
python invaders.py
# or
python pacman.py
```

### Keyboard Shortcuts (During Training)
Focus must be on the terminal/console window for keys to work.

| Key | Action |
| :--- | :--- |
| **F2** | üõë Clean stop and model save. |
| **F3** | üêû Disable Debug mode (less verbose console). |
| **F4** | üêõ Change Debug level (0-3). |
| **F5** | ‚è© Increase emulation speed (Throttle). |
| **F6** | ‚è™ Decrease emulation speed. |
| **F7** | üìä Manually generate score graph. |
| **F8** | üëÅÔ∏è Display what AI "sees" (Input Frame/State). |
| **F9** | üîÑ Toggle between **Exploration** (Learning) and **Exploitation** (Pure play) modes. |
| **F10/F11** | üéõÔ∏è Manually adjust exploration rate (Epsilon) (if NoisyNet inactive). |

---

## üìä Results Tracking
*   Logs are displayed in the console.
*   A local web server is launched on `http://localhost:5000` to view evolution graphs.
*   Models (`.pth`) and buffers (`.buffer`) are saved automatically at the root.
