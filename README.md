# MAME AI - Apprentissage Automatique pour Space Invaders (1978)

Ce projet a pour ambition de d√©velopper diff√©rentes intelligences artificielles capables de jouer au jeu d'arcade classique *Space Invaders* (version originale de 1978) en utilisant l'√©mulateur MAME. L'interaction avec l'√©mulateur se fait via un script LUA et un pont Python (PythonBridgeSocket).

L'objectif principal est d'explorer et de comparer les performances de plusieurs approches d'apprentissage par renforcement :

* **DQN-CNN (Deep Q-Network avec R√©seau de Convolution)** : Utilise l'image brute du jeu (ou une version pr√©trait√©e) comme entr√©e.
* **DQN-MLP (Deep Q-Network avec Perceptron Multicouche)** : Utilise un vecteur d'√©tat extrait de la m√©moire RAM du jeu (positions des aliens, du joueur, des tirs, etc.) comme entr√©e.
* **DreamerV2** : Un agent plus avanc√© bas√© sur un mod√®le du monde appris, capable de planifier en "r√™vant" des s√©quences futures.

## üöÄ Objectif du Projet

Le but est de cr√©er des agents IA performants pour *Space Invaders*, tout en fournissant une plateforme flexible pour exp√©rimenter avec diff√©rents algorithmes d'apprentissage par renforcement et techniques d'extraction d'√©tat dans un environnement de jeu r√©tro.

Nous cherchons √† :
1.  Impl√©menter une communication robuste entre Python et MAME via LUA.
2.  D√©velopper des extracteurs d'√©tat pertinents (RAM et/ou pixels).
3.  Entra√Æner et √©valuer les agents DQN-CNN, DQN-MLP et DreamerV2.
4.  Analyser et comparer leurs comportements, performances et vitesses d'apprentissage.
5.  Fournir des outils de visualisation pour suivre la progression de l'entra√Ænement.

## üìú Description des Fichiers

Voici un aper√ßu des principaux fichiers du projet :

### Scripts LUA (pour MAME)

* **`PythonBridgeSocket.lua`**:
    * **R√¥le** : C'est le c≈ìur de la communication c√¥t√© MAME. Ce script LUA d√©marre un serveur socket dans l'environnement MAME.
    * **Fonctionnalit√©s** :
        * Attend des connexions d'un client Python.
        * Re√ßoit des commandes du client Python (par exemple, lire/√©crire dans la m√©moire du jeu, ex√©cuter des actions de jeu comme "tirer" ou "aller √† gauche").
        * Ex√©cute ces commandes dans l'√©mulateur.
        * Renvoie les r√©sultats (par exemple, les valeurs lues en m√©moire, confirmations d'action) au client Python.
        * Utilise `zlib` pour compresser les donn√©es envoy√©es √† Python afin d'optimiser la communication.
        * G√®re la configuration des entr√©es sp√©cifiques au jeu (par exemple, les contr√¥les de Space Invaders).
        * Peut afficher des informations de d√©bogage √† l'√©cran de MAME.

### Scripts Python

* **`invaders.py`**:
    * **R√¥le** : Fichier principal orchestrant l'entra√Ænement des IA pour Space Invaders.
    * **Fonctionnalit√©s** :
        * Lance MAME avec le script LUA `PythonBridgeSocket.lua`.
        * Initialise la communication avec MAME via `MameCommunicator`.
        * Contient la boucle principale d'entra√Ænement :
            * R√©cup√®re l'√©tat du jeu (via `get_state` pour MLP ou `get_state_full_screen` pour CNN/Dreamer).
            * Demande √† l'agent IA de choisir une action.
            * Envoie l'action √† MAME pour ex√©cution.
            * Calcule la r√©compense.
            * Stocke les transitions (√©tat, action, r√©compense, nouvel √©tat, termin√©) dans le buffer de relecture.
            * Lance les √©tapes d'entra√Ænement de l'agent (`trainer.train_step()`).
        * G√®re la configuration des diff√©rents mod√®les (DQN-MLP, DQN-CNN, DreamerV2) et de leurs hyperparam√®tres.
        * D√©finit les fonctions de r√©compense.
        * G√®re la sauvegarde et le chargement des mod√®les et des buffers de relecture.
        * Produit des graphiques de performance (scores moyens, epsilon/sigma) via Matplotlib et les expose via `GraphWebServer`.
        * Permet des interactions via le clavier (d√©bogage, changement de mode, etc.).

* **`AI_Mame.py`**:
    * **R√¥le** : Contient les classes et la logique fondamentales pour les agents DQN (MLP et CNN).
    * **Composants principaux** :
        * `TrainingConfig`: Une dataclass pour stocker et g√©rer tous les hyperparam√®tres de l'entra√Ænement.
        * `GPUReplayBuffer`: Impl√©mentation d'un buffer de relecture (Experience Replay), avec support optionnel pour le Prioritized Experience Replay (PER) et l'optimisation m√©moire pour les donn√©es CNN (stockage sur CPU en `uint8`).
        * `NStepTransitionWrapper`: G√®re les transitions n-step pour le calcul des retours.
        * `NoisyLinear`: Impl√©mentation d'une couche lin√©aire "bruyante" pour l'exploration (NoisyNets).
        * `DQNModel`: L'architecture du r√©seau de neurones, supportant :
            * Des entr√©es MLP (vecteur d'√©tat).
            * Des entr√©es CNN avec diff√©rentes configurations (`deepmind`, `precise`, `original`).
            * Des options comme Dueling DQN et NoisyNets.
        * `DQNTrainer`: La classe principale pour entra√Æner les agents DQN. Elle g√®re :
            * La s√©lection d'actions (epsilon-greedy ou via NoisyNets).
            * La mise √† jour du r√©seau (calcul de la perte, r√©tropropagation).
            * La synchronisation du r√©seau cible (target network).
            * La sauvegarde et le chargement des mod√®les et des buffers.
            * La gestion du mode exploration/exploitation.
        * `GraphWebServer`: (D√©plac√© ici, mais peut aussi √™tre dans un fichier s√©par√© comme `graph_web_server.py`). Un simple serveur Flask pour afficher les graphiques de progression de l'entra√Ænement dans un navigateur web.
        * `TeeLogger`: Classe utilitaire pour rediriger les sorties `print` vers la console et un fichier de log simultan√©ment.

* **`dreamerv2.py`**:
    * **R√¥le** : Impl√©mente l'agent DreamerV2.
    * **Composants principaux** :
        * `ConvEncoder` / `ConvDecoder`: R√©seaux de convolution pour encoder les observations (images) en vecteurs latents et les d√©coder pour la reconstruction.
        * `RSSM (Recurrent State Space Model)`: Le c≈ìur de Dreamer. Un mod√®le r√©current (GRU) qui apprend √† pr√©dire les √©tats futurs latents (dynamique du monde). Il maintient un √©tat d√©terministe (`h`) et un √©tat stochastique (`z`).
        * `RewardModel`: Un r√©seau de neurones qui apprend √† pr√©dire la r√©compense √† partir des √©tats latents du RSSM.
        * `ValueModel (Critic)`: Un r√©seau de neurones qui apprend √† estimer la valeur (somme des r√©compenses futures attendues) d'un √©tat latent.
        * `ActorModel`: Un r√©seau de neurones qui apprend la politique, c'est-√†-dire quelle action prendre √† partir d'un √©tat latent.
        * `DreamerTrainer`: La classe principale pour l'entra√Ænement de l'agent DreamerV2. Elle g√®re :
            * La boucle d'apprentissage du mod√®le du monde (RSSM, encodeur/d√©codeur, mod√®le de r√©compense).
            * La boucle d'apprentissage de l'acteur et du critique en "r√™vant" des trajectoires √† partir du mod√®le du monde appris.
            * La s√©lection d'actions pendant l'interaction avec l'environnement.
            * La sauvegarde et le chargement du mod√®le complet et du buffer de relecture.

* **`MameCommSocket.py`**:
    * **R√¥le** : Client Python qui se connecte au serveur LUA `PythonBridgeSocket.lua` tournant dans MAME.
    * **Fonctionnalit√©s** :
        * √âtablit une connexion socket avec le script LUA.
        * Envoie des commandes (cha√Ænes de caract√®res) au script LUA (par exemple, `read_memory 20F8`, `execute P1_left(1)`). Les messages sont termin√©s par `__end__`.
        * Re√ßoit les r√©ponses du script LUA.
        * Utilise `zlib` pour d√©compresser les donn√©es re√ßues du script LUA.
        * Fournit une m√©thode `communicate` simple pour envoyer des requ√™tes et recevoir des r√©ponses.

* **`graph_web_server.py`**:
    * **R√¥le** : Met en place un serveur web simple utilisant Flask.
    * **Fonctionnalit√©s** :
        * Sert les images PNG (graphiques de performance g√©n√©r√©s par Matplotlib dans `invaders.py`) situ√©es dans un dossier sp√©cifi√© (par d√©faut `./graphs/`).
        * Peut √™tre configur√© pour afficher automatiquement le graphique le plus r√©cent ou une liste de tous les graphiques disponibles.
        * Permet de visualiser la progression de l'entra√Ænement √† distance via un navigateur web.

* **`ScreenRecorder.py`**:
    * **R√¥le** : Utilitaire pour interagir avec OBS (Open Broadcaster Software) via son plugin `obs-websocket`.
    * **Fonctionnalit√©s** :
        * Se connecte √† OBS.
        * Permet de d√©marrer et d'arr√™ter l'enregistrement de l'√©cran.
        * Utile pour capturer des vid√©os des performances de l'IA. (N√©cessite OBS configur√© et `obs-websocket` install√© et activ√©).

## üõ†Ô∏è Comment Utiliser (Instructions de Base)

1.  **Pr√©requis**:
    * MAME (avec la ROM Space Invaders)
    * Python 3.x
    * Biblioth√®ques Python : PyTorch, NumPy, Matplotlib, Flask, python-socketio, obswebsocket (si `ScreenRecorder.py` est utilis√©), pygame, keyboard, psutil, pywin32, colorama.
    * D√©pendances LUA pour MAME : `luasocket`, `luazlib`, `lubase64` (g√©n√©ralement incluses avec les versions r√©centes de MAME qui supportent LUA).
2.  **Configuration**:
    * V√©rifiez les chemins d'acc√®s √† l'ex√©cutable MAME et au script LUA dans `invaders.py`.
    * Placez `PythonBridgeSocket.lua` dans un endroit accessible par MAME (par exemple, le dossier `plugins` de MAME).
3.  **Lancement**:
    * Ex√©cutez `python invaders.py`.
    * Le script devrait lancer MAME, √©tablir la connexion, et commencer l'entra√Ænement.
    * Vous pouvez acc√©der √† `http://localhost:5000` (ou l'IP de votre machine sur le port 5000) pour voir les graphiques de performance.

## ü§ù Contribution

Les contributions, suggestions et rapports de bugs sont les bienvenus !
![D√©monstration de la fonctionnalit√©](1890!.gif)
